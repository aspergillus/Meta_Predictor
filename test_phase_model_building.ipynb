{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2ca2d6e7-b39d-4760-8770-d5836a902d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/var/www/html/predicationScript')\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc1297b8-f4ea-4e73-864a-21591d390222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "rndNum = '931'\n",
    "uniID = 'P51688'\n",
    "\n",
    "# rndNum = '672'\n",
    "# uniID = 'P34059'\n",
    "\n",
    "def biological_feature(df):\n",
    "    dom=pd.read_csv('../domain.csv')\n",
    "    rdv=pd.read_csv('../residual_volume.csv')\n",
    "    dd_residual_vol=[]\n",
    "    aa_RV_dict=dict(rdv.values)\n",
    "    \n",
    "    # Residual Volume\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        # Mutant Residue\n",
    "        if len(i) != 1: \n",
    "            mut_vol = math.fsum([float(aa_RV_dict.get(x)) for x in [*i]])\n",
    "        else: \n",
    "            mut_vol = aa_RV_dict.get(i)\n",
    "            \n",
    "        # Wild Residue\n",
    "        if len(j) != 1: \n",
    "            wild_vol = math.fsum([float(aa_RV_dict.get(x)) for x in [*j]])\n",
    "        else: \n",
    "            wild_vol = aa_RV_dict.get(j)\n",
    "        dd_residual_vol.append(mut_vol-wild_vol)\n",
    "    df[\"dd_changeinresidualvolume\"]=dd_residual_vol\n",
    "    \n",
    "    # # Domain and Modification from Residue to Residue\n",
    "    # dom_dom=dict(dom.drop(\"Modification\",axis=True,inplace=False).values)\n",
    "    # dom_mod=dict(dom.drop(\"Domain\",axis=True,inplace=False).values)\n",
    "    # Domain=[]\n",
    "    # Modification=[]\n",
    "    # for i in list(df[\"pos\"]):\n",
    "    #     i=int(i)\n",
    "    #     Domain.append(dom_dom.get(i))\n",
    "    #     Modification.append(dom_mod.get(i))\n",
    "    # df[\"Domain\"]=Domain\n",
    "    # df[\"Modification\"]=Modification\n",
    "\n",
    "    # Polarity and Hydrophobicity\n",
    "    pol=pd.read_csv('../polarity.csv')\n",
    "    hydrophobicity=pd.read_csv('../hydrophobicity.csv')\n",
    "    aa_pol_dic=dict(pol.values)\n",
    "    aa_hydro_dic=dict(hydrophobicity.values)\n",
    "    dd_pol=[]\n",
    "    dd_hydrophobicity=[]\n",
    "    \n",
    "    # Polarity\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        # Mutant Residue\n",
    "        if len(i) != 1: \n",
    "            mut_pol = math.fsum([float(aa_pol_dic.get(x)) for x in [*i]])\n",
    "        else: \n",
    "            mut_pol = aa_pol_dic.get(i)\n",
    "            \n",
    "        # Wild Residue\n",
    "        if len(j) != 1: \n",
    "            wild_pol = math.fsum([float(aa_pol_dic.get(x)) for x in [*j]])\n",
    "        else: \n",
    "            wild_pol = aa_pol_dic.get(j)\n",
    "        dd_pol.append(mut_pol-wild_pol)\n",
    "        \n",
    "    # Hydrophobicity\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        # Mutant Residue\n",
    "        if len(i) != 1: \n",
    "            mut_hydro = math.fsum([float(aa_hydro_dic.get(x)) for x in [*i]])\n",
    "        else: \n",
    "            mut_hydro = aa_hydro_dic.get(i)\n",
    "            \n",
    "        # Wild Residue\n",
    "        if len(j) != 1: \n",
    "            wild_hydro = math.fsum([float(aa_hydro_dic.get(x)) for x in [*j]])\n",
    "        else: \n",
    "            wild_hydro = aa_hydro_dic.get(j)\n",
    "        dd_hydrophobicity.append(mut_hydro-wild_hydro)\n",
    "\n",
    "    df[\"dd_polarity\"]=dd_pol\n",
    "    df[\"dd_hydrophobicity\"]=dd_hydrophobicity\n",
    "    return df\n",
    "\n",
    "def create_class(df):\n",
    "    mutation=df[\"Mutation\"]\n",
    "    mutation=list(mutation)\n",
    "    wild=[]\n",
    "    atlaa=[]\n",
    "    pos=[]\n",
    "    for ele in mutation:\n",
    "        eleLst = re.split('(\\d+)',ele)\n",
    "        wild.append(eleLst[0])\n",
    "        atlaa.append(eleLst[2])\n",
    "        pos.append(eleLst[1])\n",
    "    return([wild,atlaa,pos])\n",
    "\n",
    "prntDir = os.getcwd().rsplit('/',1)[0]\n",
    "os.chdir(f\"{prntDir}/fileUpload/{rndNum}/outFiles\")\n",
    "tools = sorted(os.listdir())\n",
    "feature = []\n",
    "for i in tools:\n",
    "    feature.append(i.split('.')[0] + '_score')\n",
    "df = pd.DataFrame()\n",
    "Mut = pd.read_csv('../mutation.txt', header=None)\n",
    "df[\"Mutation\"] = Mut\n",
    "empty_df = []\n",
    "for i,j in zip(tools,feature):\n",
    "    if pd.read_csv(i).empty:\n",
    "        empty_df = i\n",
    "    else:\n",
    "        outF = pd.read_csv(i)\n",
    "        df[j] =  df['Mutation'].map(outF.set_index('Mutation')['Score'])\n",
    "        df = df.fillna(0)\n",
    "mut_info = create_class(df)\n",
    "df.insert(1,\"Wild\",mut_info[0])\n",
    "df.insert(2,\"Mutant\",mut_info[1])\n",
    "df.insert(3,\"pos\",list(map(int, mut_info[2])))\n",
    "# new_df = biological_feature(df)\n",
    "new_df = df\n",
    "\n",
    "# adding Clinical Features to the dataframe\n",
    "cliniFile = pd.read_csv('../MPS_IIIA_Clinical_Significance.csv', names=['Mut','clinical'])\n",
    "new_df['clinical_phenotype'] = new_df.Mutation.map(cliniFile.set_index('Mut')['clinical']).fillna(0).astype(int)\n",
    "\n",
    "# clinPheno = []\n",
    "# import requests\n",
    "# url='https://rest.uniprot.org/uniprot/'+uniID+''\n",
    "# data = requests.get(url).json()\n",
    "# for i in range(len(data['features'])):\n",
    "#     if data['features'][i]['type'] == 'Natural variant':\n",
    "#         if 'severe' in data['features'][i]['description']:\n",
    "#             clinPheno.append(data['features'][i]['location']['start']['value'])\n",
    "# commSet = list(set(clinPheno) & set(list(map(int, new_df['pos'].tolist()))))\n",
    "# new_df['clinical_phenotype'] = ''\n",
    "# c = 0\n",
    "# for i in list(new_df['pos']):\n",
    "#     if i in commSet:\n",
    "#         new_df['clinical_phenotype'][c] = 1\n",
    "#     else:\n",
    "#         new_df['clinical_phenotype'][c] = 0\n",
    "#     c+=1\n",
    "# new_df.to_csv(\"../train_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0c29d0ce-4a95-4b4f-b590-b63f5cdb7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ddae7d99-661f-41d6-9a16-269aa5908c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop([\"Mutation\",\"Wild\",\"Mutant\",\"pos\",\"clinical_phenotype\"],axis=True).apply(pd.to_numeric, errors = 'coerce')\n",
    "y = pd.DataFrame(new_df['clinical_phenotype'], columns=['clinical_phenotype']).apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 32)\n",
    "model = LogisticRegression()\n",
    "ss = StandardScaler()\n",
    "X_train = pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test = pd.DataFrame(ss.transform(X_test),columns=X_test.columns)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Dump model for MPS_III_A\n",
    "pickle.dump(model, open('../MPS_III_A.pkl', 'wb'))\n",
    "pickle.dump(ss, open('../Scaler_MPS_III_A.pkl', 'wb'))\n",
    "\n",
    "# for i in range(1, 80):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = i)\n",
    "#     model = LogisticRegression()\n",
    "#     ss = StandardScaler()\n",
    "#     X_train = pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns)\n",
    "#     X_test = pd.DataFrame(ss.transform(X_test),columns=X_test.columns)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"{i}: {matthews_corrcoef(y_test, y_pred)}\")\n",
    "\n",
    "# model.score(X_test, y_test)\n",
    "# Dump model for MPS_III_A\n",
    "# pickle.dump(model, open('../MPS_III_A.pkl', 'wb'))\n",
    "# pickle.dump(ss, open('../Scaler_MPS_III_A.pkl', 'wb'))\n",
    "\n",
    "# print(model.predict(X_test))\n",
    "# print(list(y_test.clinical_phenotype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0325a487-b3d5-41bd-966f-df1f9db8030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop([\"Mutation\",\"Wild\",\"Mutant\",\"pos\",\"clinical_phenotype\"],axis=True)\n",
    "y = pd.DataFrame(new_df['clinical_phenotype'], columns=['clinical_phenotype'])\n",
    "ConvX = X.apply(pd.to_numeric, errors = 'coerce')\n",
    "ConvY = y.apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# X_train, X_test, y_train, y_test = train_test_split(ConvX, ConvY, test_size=0.2, random_state=42)\n",
    "# ss = StandardScaler()\n",
    "# ss_train = pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns)\n",
    "# ss_test = pd.DataFrame(ss.transform(X_test),columns=X_test.columns)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss_train = pd.DataFrame(ss.fit_transform(ConvX),columns=ConvX.columns)\n",
    "model = LogisticRegression()\n",
    "model.fit(ss_train, ConvY)\n",
    "\n",
    "# # Dump model for MPS_IV_A \n",
    "# pickle.dump(model, open('../MPS_IV_A.pkl', 'wb'))\n",
    "# pickle.dump(ss, open('../Scaler_MPS_IV_A.pkl', 'wb'))\n",
    "\n",
    "# Dump model for MPS_III_A\n",
    "pickle.dump(model, open('../MPS_III_A.pkl', 'wb'))\n",
    "pickle.dump(ss, open('../Scaler_MPS_III_A.pkl', 'wb'))\n",
    "\n",
    "# y_predicted = model.predict(ss_test)\n",
    "# dumm = np.where(y_predicted == 0,\"neutral\",\"severe\")\n",
    "# test_mut[\"predicted\"] = dumm\n",
    "# prob=model.predict_proba(ss_test)\n",
    "# LR_prob=[]\n",
    "# for i,j in zip(y_predicted,prob):\n",
    "#     LR_prob.append(j[i])\n",
    "# test_mut[\"probability\"]=LR_prob\n",
    "# result = pd.DataFrame(map(getMutation, sorted(X_test.index)), columns=['Mutation'])\n",
    "# final_df = pd.concat([result,test_mut],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f892856f-6ff8-4a71-9e7a-ed88b7988082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "8e1e1478-58ec-4f39-8e2f-cf1eb5f37751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 3],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "b331234d-0ac6-41c7-9753-5f109bf436a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    clinical_phenotype\n",
      "53                   0\n",
      "60                   1\n",
      "0                    0\n",
      "45                   0\n",
      "5                    1\n",
      "61                   0\n",
      "16                   0\n",
      "12                   0\n",
      "64                   0\n",
      "30                   0\n",
      "33                   0\n",
      "9                    0\n",
      "41                   0\n",
      "[0 0 0 0 1 0 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "b8528f80-4c81-4b5a-83a8-140b067a321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.17766726362967536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, matthews_corrcoef\n",
    "print(recall_score(y_test, y_predicted))\n",
    "print(matthews_corrcoef(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32a2fc39-72ff-48d7-8188-60165785fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mutation predicted  probability\n",
      "0         M1A   neutral     0.969416\n",
      "1         M1D   neutral     0.946433\n",
      "2         M1H   neutral     0.927172\n",
      "3         M1L   neutral     0.906791\n",
      "4         M1F   neutral     0.981369\n",
      "...       ...       ...          ...\n",
      "1903    E501D   neutral     0.909142\n",
      "1904    E501K   neutral     0.995764\n",
      "1905    L502H   neutral     0.992237\n",
      "1906    L502F   neutral     0.994555\n",
      "1907    L502Y   neutral     0.945940\n",
      "\n",
      "[1908 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def getMutation(indexNum):\n",
    "    res = new_df['Mutation'][indexNum]\n",
    "    return res\n",
    "\n",
    "X = new_df.drop([\"Mutation\",\"Wild\",\"Mutant\",\"pos\",\"clinical_phenotype\"],axis=True)\n",
    "y = pd.DataFrame(new_df['clinical_phenotype'], columns=['clinical_phenotype'])\n",
    "ConvX = X.apply(pd.to_numeric, errors = 'coerce')\n",
    "ConvY = y.apply(pd.to_numeric, errors = 'coerce')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ConvX, ConvY, test_size=0.2, random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss_train = pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns)\n",
    "ss_test = pd.DataFrame(ss.transform(X_test),columns=X_test.columns)\n",
    "model = LogisticRegression(penalty='l2',dual=False,tol=1e-8,\n",
    "                      C=0.05,fit_intercept=True,class_weight={0:0.957,1:2.6},random_state=14,solver='liblinear')\n",
    "test_mut = pd.DataFrame()\n",
    "model.fit(ss_train,y_train)\n",
    "y_predicted=model.predict(ss_test)\n",
    "dumm=np.where(y_predicted==0,\"neutral\",\"severe\")\n",
    "test_mut[\"predicted\"]=dumm\n",
    "prob=model.predict_proba(ss_test)\n",
    "LR_prob=[]\n",
    "for i,j in zip(y_predicted,prob):\n",
    "    LR_prob.append(j[i])\n",
    "test_mut[\"probability\"]=LR_prob\n",
    "result = pd.DataFrame(map(getMutation, sorted(X_test.index)), columns=['Mutation'])\n",
    "final_df=pd.concat([result,test_mut],axis=1)\n",
    "print(final_df)\n",
    "final_df.to_csv(\"../ModelPrediction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d21bf6c5-7023-43de-bed6-d0949e72ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/www/html/fileUpload/672/outFiles'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b2f398-7ed7-4044-ba76-9f28476194a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "fcf4b8f2-83a6-40ae-aa4c-b20a56d07113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fee9353-cfb3-4295-99e8-8f57f874a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('../MPS_III_A.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "79e99b5d-8af9-4697-8cef-7b47f696c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "essColumn = ['duet_score', 'foldX_score', 'iMutant_score', 'mCSM_score', 'maestro_score', \n",
    "             'metaSNP_score', 'muPro_score', 'polyphen2_score', 'sdm_score', 'snpsGO_score', \n",
    "             'dd_changeinresidualvolume', 'Domain', 'Modification', 'dd_polarity',\n",
    "             'dd_hydrophobicity']\n",
    "X_test_2 = X_test.drop([\"duet_score\",\"iMutant_score\"],axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "a6629670-2e85-4a2f-a952-262e6acd5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "4fbe4394-3c1b-4b8a-bdef-46bfa30349df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ec in enumerate(essColumn, 0):\n",
    "    if ec[1] not in X_test_2.columns:\n",
    "        X_test_2.insert(ec[0], ec[1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "f7b9bff6-12d1-42e3-b7d5-88862082b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "070a0b1c-deb9-4be7-8436-2bc2c1173df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duet_score</th>\n",
       "      <th>foldX_score</th>\n",
       "      <th>iMutant_score</th>\n",
       "      <th>mCSM_score</th>\n",
       "      <th>maestro_score</th>\n",
       "      <th>metaSNP_score</th>\n",
       "      <th>muPro_score</th>\n",
       "      <th>polyphen2_score</th>\n",
       "      <th>sdm_score</th>\n",
       "      <th>snpsGO_score</th>\n",
       "      <th>dd_changeinresidualvolume</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Modification</th>\n",
       "      <th>dd_polarity</th>\n",
       "      <th>dd_hydrophobicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>3.30569</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.07693</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.240278</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.068</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>2.84244</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.18647</td>\n",
       "      <td>0.853</td>\n",
       "      <td>-0.622768</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.879</td>\n",
       "      <td>26.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.04868</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.17416</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.420749</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.781</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>3.09165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.06610</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-1.086024</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.118</td>\n",
       "      <td>20.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>17.97060</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.241</td>\n",
       "      <td>-0.15722</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.997</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.471</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    duet_score  foldX_score  iMutant_score  mCSM_score  maestro_score  \\\n",
       "53           0      3.30569              0      -0.824       -0.07693   \n",
       "60           0      2.84244              0      -0.586        0.18647   \n",
       "0            0      2.04868              0      -0.423        0.17416   \n",
       "45           0      3.09165              0       0.143        1.06610   \n",
       "5            0     17.97060              0      -1.241       -0.15722   \n",
       "\n",
       "    metaSNP_score  muPro_score  polyphen2_score  sdm_score  snpsGO_score  \\\n",
       "53          0.174    -0.240278            0.001      -0.38         0.068   \n",
       "60          0.853    -0.622768            1.000      -0.03         0.879   \n",
       "0           0.808    -0.420749            1.000      -0.29         0.781   \n",
       "45          0.440    -1.086024            1.000      -0.86         0.118   \n",
       "5           0.814     0.066215            0.997      -0.11         0.471   \n",
       "\n",
       "    dd_changeinresidualvolume  Domain  Modification  dd_polarity  \\\n",
       "53                       19.4       2             0          0.0   \n",
       "60                       26.3       3             0         -5.1   \n",
       "0                        16.3       1             0         -0.7   \n",
       "45                       20.4       2             0         -1.0   \n",
       "5                        80.5       1             0         -3.8   \n",
       "\n",
       "    dd_hydrophobicity  \n",
       "53               0.60  \n",
       "60               2.05  \n",
       "0                0.01  \n",
       "45               0.68  \n",
       "5                2.60  "
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8d39b272-9e35-41c5-bd8e-d91795f879e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "36f22aae-8f24-4834-91ba-68622dc6220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "cb4b5a51-37dd-4f50-ac2a-f115c04e7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_2 = X_test_2.iloc[:, :-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "138d7049-fe13-48ab-a3a6-d9b8ed96cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "e680a58f-98dd-4cf9-acea-74b6392a3849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.60177062, 0.39822938]),\n",
       " array([0.49157132, 0.50842868]),\n",
       " array([0.58998951, 0.41001049]),\n",
       " array([0.66318006, 0.33681994]),\n",
       " array([0.58752686, 0.41247314]),\n",
       " array([0.67119061, 0.32880939]),\n",
       " array([0.63190694, 0.36809306]),\n",
       " array([0.80529629, 0.19470371]),\n",
       " array([0.64664707, 0.35335293]),\n",
       " array([0.56612999, 0.43387001]),\n",
       " array([0.4917133, 0.5082867]),\n",
       " array([0.55558095, 0.44441905]),\n",
       " array([0.46134536, 0.53865464])]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model = pickle.load(open('MPS_III_A.pkl', 'rb'))\n",
    "# pickled_model.predict(X_test_2)\n",
    "list(pickled_model.predict_proba(X_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "48509c79-abe8-4edb-9048-30ed488dd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "237b5375-439b-4c0c-b4e2-0fa7821b4e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ####### Feature Scaling ######\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "# classifier = LogisticRegression()\n",
    "# parameter = {'penalty':['l1', 'l2', 'elasticnet'], 'C':[0.5,1,1.5,2,4,5,6,7,10,20,30,50], 'max_iter': [100, 200, 300]}\n",
    "# # {'C': 2, 'max_iter': 100, 'penalty': 'l2'} #### Got this parameter with 0.72 accuracy rate\n",
    "# classifier_regressor = GridSearchCV(classifier, param_grid = parameter, scoring='accuracy', cv=5)\n",
    "# classifier_regressor.fit(ConvX, ConvY)\n",
    "# print(classifier_regressor.best_params_)\n",
    "# print(classifier_regressor.best_score_)\n",
    "# y_pred = classifier_regressor.predict(ss_test)\n",
    "# accr_score = accuracy_score(y_pred, y_test)\n",
    "# print(accr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1d674965-8404-4455-98bf-3f656c055ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "# tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2db39ada-8db4-4730-b2db-b65f8d3e17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc  = tp + tn / tp + fp + tn + fn\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "442adb44-7414-4263-9145-de25e224efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df.to_csv(\"../test_purpose.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "ede52cc3-0c80-4681-8852-dd110a713305",
   "metadata": {},
   "outputs": [],
   "source": [
    "dom=pd.read_csv('../domain.csv')\n",
    "rdv=pd.read_csv('../residual_volume.csv')\n",
    "dd_residual_vol=[]\n",
    "aa_RV_dict=dict(rdv.values)\n",
    "# for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "#     mut_vol=aa_RV_dict.get(i)\n",
    "#     wild_vol=aa_RV_dict.get(j)\n",
    "    # print(wild_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "fc195a17-e5d5-44a6-9fcd-fc1a4d0e80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa_RV_dict\n",
    "# test_mut_vol = aa_RV_dict.get('N')\n",
    "# # print([*strMut])\n",
    "# test_mut_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3632f7a5-d4dd-4183-a086-6b0a969b752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strMut = df[\"Mutant\"][54]\n",
    "# if len(strMut) > 0:\n",
    "#     print(strMut.split())\n",
    "# else:\n",
    "#     print('NO')\n",
    "# # len(strMut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "6b92be2b-30da-47ed-8bc3-800c25da6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(strMut) != 1: \n",
    "#     sptStr = [*strMut]\n",
    "# else: \n",
    "#     print(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "bd89fa3b-70a7-45c4-b105-0d6bb899f944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91.9, 89.7, 109.1]"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sptStr\n",
    "# if len(strMut) != 1: \n",
    "#     print('yes') \n",
    "# else:\n",
    "#     print('No')\n",
    "# print(abc)\n",
    "resVol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "6561357b-d3b8-4aef-b01b-4b515731d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290.7\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "resVol = math.fsum([float(aa_RV_dict.get(x)) for x in [*strMut]])\n",
    "print(resVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77843b94-e8ec-4717-9bce-0ba825828d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "290.70000000000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a75d03-2b47-4139-bbac-637f1c069587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biological_feature(df):\n",
    "    dom=pd.read_csv('../domain.csv')\n",
    "    rdv=pd.read_csv('../residual_volume.csv')\n",
    "    dd_residual_vol=[]\n",
    "    aa_RV_dict=dict(rdv.values)\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        mut_vol=aa_RV_dict.get(i)\n",
    "        wild_vol=aa_RV_dict.get(j)\n",
    "        dd_residual_vol.append(mut_vol-wild_vol)\n",
    "    df[\"dd_changeinresidualvolume\"]=dd_residual_vol\n",
    "    dom_dom=dict(dom.drop(\"Modification\",axis=True,inplace=False).values)\n",
    "    dom_mod=dict(dom.drop(\"Domain\",axis=True,inplace=False).values)\n",
    "    Domain=[]\n",
    "    Modification=[]\n",
    "    for i in list(df[\"pos\"]):\n",
    "        i=int(i)\n",
    "        Domain.append(dom_dom.get(i))\n",
    "        Modification.append(dom_mod.get(i))\n",
    "    df[\"Domain\"]=Domain\n",
    "    df[\"Modification\"]=Modification\n",
    "\n",
    "    ####polarity######\n",
    "    pol=pd.read_csv('../polarity.csv')\n",
    "    hydrophobicity=pd.read_csv('../hydrophobicity.csv')\n",
    "    aa_pol_dic=dict(pol.values)\n",
    "    aa_hydro_dic=dict(hydrophobicity.values)\n",
    "    dd_pol=[]\n",
    "    dd_hydrophobicity=[]\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        mut_pol=aa_pol_dic.get(i)\n",
    "        wild_pol=aa_pol_dic.get(j)\n",
    "        dd_pol.append(mut_pol-wild_pol)\n",
    "    for i,j in zip(df[\"Mutant\"],df[\"Wild\"]):\n",
    "        mut_hydro=aa_hydro_dic.get(i)\n",
    "        wild_hydro=aa_hydro_dic.get(j)\n",
    "        dd_hydrophobicity.append(mut_hydro-wild_hydro)\n",
    "\n",
    "    df[\"dd_polarity\"]=dd_pol\n",
    "    df[\"dd_hydrophobicity\"]=dd_hydrophobicity\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e5d9b-17c0-436b-957e-e9cee15fb556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b6fbc-852f-48c0-aae7-dc3d3769c319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5ad88-3829-4620-8cc2-a1be23b5c602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a8d0d70-bcce-4d6d-a75d-6cfa00137033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mutation predicted  probability\n",
      "0    D179N   Neutral     0.556853\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.chdir('/var/www/html')\n",
    "# os.getcwd()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rndNum = 480\n",
    "selMod = \"SGSH\"\n",
    "# rndNum = sys.argv[1]\n",
    "# selMod = sys.argv[2]\n",
    "# essColumn = ['duet_score', 'foldX_score', 'iMutant_score', 'mCSM_score', 'maestro_score', \n",
    "#              'metaSNP_score', 'muPro_score', 'polyphen2_score', 'sdm_score', 'snpsGO_score', \n",
    "#              'dd_changeinresidualvolume', 'Domain', 'Modification', 'dd_polarity',\n",
    "#              'dd_hydrophobicity']\n",
    "prntDir = os.getcwd()\n",
    "os.chdir(f\"{prntDir}/fileUpload/{rndNum}\")\n",
    "if (selMod == 'SGSH'):\n",
    "    model = 'MPS_III_A'\n",
    "    StandardScalar = 'Scaler_MPS_III_A'\n",
    "else:\n",
    "    model = 'MPS_IV_A'\n",
    "    StandardScalar = 'Scaler_MPS_IV_A'\n",
    "\n",
    "# pre-Processing data for the prediction\n",
    "df=pd.read_csv(\"train_set.csv\")\n",
    "X = df.drop([\"Mutation\",\"Wild\",\"Mutant\",\"pos\",\"clinical_phenotype\"],axis=True)\n",
    "y = pd.DataFrame(df['clinical_phenotype'], columns=['clinical_phenotype'])\n",
    "ConvX = X.apply(pd.to_numeric, errors = 'coerce')\n",
    "ConvY = y.apply(pd.to_numeric, errors = 'coerce')\n",
    "# ss = pickle.load(open(f\"{prntDir}/featureModel/{StandardScalar}.pkl\", 'rb'))\n",
    "# ConvX = pd.DataFrame(ss.transform(ConvX),columns=ConvX.columns)\n",
    "\n",
    "# for ec in enumerate(essColumn, 0):\n",
    "#     if ec[1] not in ss_test.columns:\n",
    "#         ss_test.insert(ec[0], ec[1], 0)\n",
    "\n",
    "# maestro, mCSM, muPro\n",
    "ConvX = ConvX.drop(['mCSM_score', 'maestro_score', 'muPro_score'], axis=1)\n",
    "\n",
    "# Predication \n",
    "new_df = pd.DataFrame(df['Mutation'], columns=['Mutation'])\n",
    "pickled_model = pickle.load(open(f\"{prntDir}/featureModel/{model}.pkl\", 'rb'))\n",
    "predLst = pickled_model.predict(ConvX)\n",
    "dumm=np.where(predLst==0,\"Neutral\",\"Severe\")\n",
    "new_df[\"predicted\"]=dumm\n",
    "prdProbLst = pickled_model.predict_proba(ConvX)\n",
    "LR_prob = []\n",
    "for i,j in zip(predLst,prdProbLst):\n",
    "    LR_prob.append(j[i])\n",
    "new_df[\"probability\"] = LR_prob\n",
    "new_df.to_csv(\"ModelPrediction.csv\",index=False)\n",
    "print(new_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
